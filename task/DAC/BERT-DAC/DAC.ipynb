{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e8c42d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79825642",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir THUCNews/saved_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2af63d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model='bert', save_path='bert_predictions.npz')\n",
      "bert\n",
      "Loading data...\n",
      "98529it [00:09, 10757.29it/s]\n",
      "33267it [00:03, 10405.47it/s]\n",
      "32935it [00:03, 10472.53it/s]\n",
      "Time usage: 0:00:16\n",
      "Epoch [1/3]\n",
      "/paddle/imcs21/task/DAC/BERT-DAC/pytorch_pretrained/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)\n",
      "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Iter:      0,  Val P: 0.04433,  Val R: 5.9731%,  Val F1: 0.02457,  Val Acc: 6.0120%,  Time: 0:01:03 *\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Iter:    100,  Val P: 0.6554,  Val R: 54.4174%,  Val F1: 0.5354,  Val Acc: 72.6396%,  Time: 0:03:24 *\n",
      "Iter:    200,  Val P: 0.7678,  Val R: 61.1379%,  Val F1: 0.6587,  Val Acc: 75.8830%,  Time: 0:05:44 *\n",
      "Iter:    300,  Val P: 0.6778,  Val R: 70.0418%,  Val F1: 0.6585,  Val Acc: 73.7127%,  Time: 0:08:04 \n",
      "Iter:    400,  Val P: 0.7297,  Val R: 71.8843%,  Val F1: 0.7197,  Val Acc: 78.4080%,  Time: 0:10:24 *\n",
      "Iter:    500,  Val P: 0.7418,  Val R: 70.5496%,  Val F1: 0.7086,  Val Acc: 77.8429%,  Time: 0:12:44 \n",
      "Iter:    600,  Val P: 0.7676,  Val R: 65.9484%,  Val F1: 0.6889,  Val Acc: 78.1195%,  Time: 0:15:05 *\n",
      "Iter:    700,  Val P: 0.7726,  Val R: 69.7477%,  Val F1: 0.721,  Val Acc: 79.0994%,  Time: 0:17:26 *\n",
      "Epoch [2/3]\n",
      "Iter:    800,  Val P: 0.7438,  Val R: 74.2236%,  Val F1: 0.7362,  Val Acc: 79.7758%,  Time: 0:19:48 *\n",
      "Iter:    900,  Val P: 0.7118,  Val R: 75.3888%,  Val F1: 0.7279,  Val Acc: 78.1706%,  Time: 0:22:10 \n",
      "Iter:   1000,  Val P: 0.7337,  Val R: 74.2348%,  Val F1: 0.7322,  Val Acc: 79.5984%,  Time: 0:24:32 \n",
      "Iter:   1100,  Val P: 0.7758,  Val R: 70.8424%,  Val F1: 0.7353,  Val Acc: 80.2447%,  Time: 0:26:56 *\n",
      "Iter:   1200,  Val P: 0.7654,  Val R: 73.0704%,  Val F1:  0.74,  Val Acc: 80.3770%,  Time: 0:29:19 *\n",
      "Iter:   1300,  Val P: 0.7827,  Val R: 69.6836%,  Val F1: 0.7313,  Val Acc: 79.6224%,  Time: 0:31:42 \n",
      "Iter:   1400,  Val P: 0.7255,  Val R: 77.1659%,  Val F1: 0.7449,  Val Acc: 79.8118%,  Time: 0:34:04 \n",
      "Iter:   1500,  Val P: 0.7303,  Val R: 77.1252%,  Val F1: 0.7463,  Val Acc: 79.6585%,  Time: 0:36:28 *\n",
      "Epoch [3/3]\n",
      "Iter:   1600,  Val P: 0.7586,  Val R: 73.9847%,  Val F1: 0.7411,  Val Acc: 80.3198%,  Time: 0:38:51 *\n",
      "Iter:   1700,  Val P: 0.7765,  Val R: 71.8255%,  Val F1: 0.7398,  Val Acc: 80.6144%,  Time: 0:41:14 \n",
      "Iter:   1800,  Val P: 0.752,  Val R: 74.8419%,  Val F1: 0.7461,  Val Acc: 80.8339%,  Time: 0:43:37 \n",
      "Iter:   1900,  Val P: 0.7809,  Val R: 71.9305%,  Val F1: 0.7443,  Val Acc: 81.0082%,  Time: 0:46:00 \n",
      "Iter:   2000,  Val P: 0.771,  Val R: 73.7587%,  Val F1: 0.7504,  Val Acc: 81.2156%,  Time: 0:48:23 \n",
      "Iter:   2100,  Val P: 0.7601,  Val R: 74.8632%,  Val F1: 0.7529,  Val Acc: 81.0232%,  Time: 0:50:46 *\n",
      "Iter:   2200,  Val P: 0.7541,  Val R: 75.8323%,  Val F1: 0.7547,  Val Acc: 81.0713%,  Time: 0:53:09 \n",
      "Iter:   2300,  Val P: 0.7532,  Val R: 76.4549%,  Val F1: 0.7573,  Val Acc: 81.1164%,  Time: 0:55:33 *\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test P: 0.0625, Test R: 0.0005902, Test F: 0.001169,  Test Acc: 0.9443%\n",
      "Precision, Recall and F1-Score...\n",
      "                                            precision    recall  f1-score   support\n",
      "\n",
      "                          Request-Etiology     1.0000    0.0094    0.0187     32935\n",
      "                       Request-Precautions     0.0000    0.0000    0.0000         0\n",
      "                    Request-Medical_Advice     0.0000    0.0000    0.0000         0\n",
      "                           Inform-Etiology     0.0000    0.0000    0.0000         0\n",
      "                                  Diagnose     0.0000    0.0000    0.0000         0\n",
      "                 Request-Basic_Information     0.0000    0.0000    0.0000         0\n",
      "               Request-Drug_Recommendation     0.0000    0.0000    0.0000         0\n",
      "                     Inform-Medical_Advice     0.0000    0.0000    0.0000         0\n",
      "Request-Existing_Examination_and_Treatment     0.0000    0.0000    0.0000         0\n",
      "                  Inform-Basic_Information     0.0000    0.0000    0.0000         0\n",
      "                        Inform-Precautions     0.0000    0.0000    0.0000         0\n",
      " Inform-Existing_Examination_and_Treatment     0.0000    0.0000    0.0000         0\n",
      "                Inform-Drug_Recommendation     0.0000    0.0000    0.0000         0\n",
      "                           Request-Symptom     0.0000    0.0000    0.0000         0\n",
      "                            Inform-Symptom     0.0000    0.0000    0.0000         0\n",
      "                                     Other     0.0000    0.0000    0.0000         0\n",
      "\n",
      "                                  accuracy                         0.0094     32935\n",
      "                                 macro avg     0.0625    0.0006    0.0012     32935\n",
      "                              weighted avg     1.0000    0.0094    0.0187     32935\n",
      "\n",
      "Confusion Matrix...\n",
      "[[  311   374   490   528   815   988  1042  1156  1325  1441  1761  1836\n",
      "   2284  3049  4869 10666]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "Time usage: 0:01:03\n",
      "saving predictions to bert_predictions.npz.\n"
     ]
    }
   ],
   "source": [
    "!python run.py --model bert --save_path bert_predictions.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "81b10c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model='bert', save_path='bert_predictions1.npz')\n",
      "bert\n",
      "Loading data...\n",
      "98529it [00:08, 10972.61it/s]\n",
      "33267it [00:03, 10734.60it/s]\n",
      "25310it [00:02, 10624.27it/s]\n",
      "Time usage: 0:00:14\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Test P: 0.0625, Test R: 0.0005927, Test F: 0.001174,  Test Acc: 0.9482%\n",
      "Precision, Recall and F1-Score...\n",
      "                                            precision    recall  f1-score   support\n",
      "\n",
      "                          Request-Etiology     1.0000    0.0095    0.0188     25310\n",
      "                       Request-Precautions     0.0000    0.0000    0.0000         0\n",
      "                    Request-Medical_Advice     0.0000    0.0000    0.0000         0\n",
      "                           Inform-Etiology     0.0000    0.0000    0.0000         0\n",
      "                                  Diagnose     0.0000    0.0000    0.0000         0\n",
      "                 Request-Basic_Information     0.0000    0.0000    0.0000         0\n",
      "               Request-Drug_Recommendation     0.0000    0.0000    0.0000         0\n",
      "                     Inform-Medical_Advice     0.0000    0.0000    0.0000         0\n",
      "Request-Existing_Examination_and_Treatment     0.0000    0.0000    0.0000         0\n",
      "                  Inform-Basic_Information     0.0000    0.0000    0.0000         0\n",
      "                        Inform-Precautions     0.0000    0.0000    0.0000         0\n",
      " Inform-Existing_Examination_and_Treatment     0.0000    0.0000    0.0000         0\n",
      "                Inform-Drug_Recommendation     0.0000    0.0000    0.0000         0\n",
      "                           Request-Symptom     0.0000    0.0000    0.0000         0\n",
      "                            Inform-Symptom     0.0000    0.0000    0.0000         0\n",
      "                                     Other     0.0000    0.0000    0.0000         0\n",
      "\n",
      "                                  accuracy                         0.0095     25310\n",
      "                                 macro avg     0.0625    0.0006    0.0012     25310\n",
      "                              weighted avg     1.0000    0.0095    0.0188     25310\n",
      "\n",
      "Confusion Matrix...\n",
      "[[ 240  301  344  445  640  694  856  840  928 1043 1405 1348 1907 2458\n",
      "  3797 8064]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Time usage: 0:00:45\n",
      "saving predictions to bert_predictions1.npz.\n"
     ]
    }
   ],
   "source": [
    "!python run.py --model bert --save_path bert_predictions1.npz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b60d5be",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ca37c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39215d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "data_dir = '../../../dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "16c042fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('bert_predictions1.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f79ddffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.files # ['test_confusion', 'test_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91f69ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a[a.files[1]] # array([13, 14, 14, ...,  7, 15, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "42db6e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.Series(a[a.files[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa7b4608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25310,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "98cec35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15\n",
       "1    14\n",
       "2    13\n",
       "3    14\n",
       "4    14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20a03f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = r.map(id2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25fce2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              Other\n",
       "1     Inform-Symptom\n",
       "2    Request-Symptom\n",
       "3     Inform-Symptom\n",
       "4     Inform-Symptom\n",
       "dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "35c10cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = load_json(os.path.join(data_dir, 'test.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f561710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set\n",
    "# {'10035922': {'self_report': '小孩5岁，从6月至今，总是间接性咳嗽，偶尔有痰，不思饮食，中间吃过头孢克洛，阿莫西林，止咳糖浆，盐酸溴索口服液，利巴韦林喷剂等药，总是时好时犯，请问怎么办，谢谢医生',\n",
    "#   'explicit_info': {'Symptom': ['咳嗽', '痰']},\n",
    "#   'dialogue': [{'sentence_id': '1',\n",
    "#     'speaker': '医生',\n",
    "#     'sentence': '这个孩子除了咳嗽以外，还有其他的症状吗？'},\n",
    "#    {'sentence_id': '2', 'speaker': '患者', 'sentence': '前1周有脖子处淋巴结肿大'},\n",
    "#    {'sentence_id': '3', 'speaker': '患者', 'sentence': '发烧'},\n",
    "#    {'sentence_id': '4', 'speaker': '医生', 'sentence': '这个孩子断断续续的咳嗽有多长时间了？'},\n",
    "#    {'sentence_id': '5', 'speaker': '患者', 'sentence': '7月份至今'},\n",
    "#    {'sentence_id': '6', 'speaker': '医生', 'sentence': '你都进行过什么检查？'},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "52fdb82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\n",
    "    'Request-Etiology', 'Request-Precautions', 'Request-Medical_Advice', 'Inform-Etiology', 'Diagnose',\n",
    "    'Request-Basic_Information', 'Request-Drug_Recommendation', 'Inform-Medical_Advice',\n",
    "    'Request-Existing_Examination_and_Treatment', 'Inform-Basic_Information', 'Inform-Precautions',\n",
    "    'Inform-Existing_Examination_and_Treatment', 'Inform-Drug_Recommendation', 'Request-Symptom',\n",
    "    'Inform-Symptom', 'Other'\n",
    "]\n",
    "id2tag = {idx:tag for idx, tag in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f02b5b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = {}\n",
    "i = 0\n",
    "for pid, sample in test_set.items():\n",
    "    td = {}\n",
    "    for sent in sample['dialogue']:\n",
    "        td[sent['sentence_id']] = r1.iloc[i]\n",
    "        \n",
    "        i += 1\n",
    "    rd[pid] = td\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "49cf58c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def write2json_file(fp, data, encoding='utf-8'):\n",
    "    \"\"\"\n",
    "    Converts arbitrary object recursively into JSON file. \n",
    "    Use ensure_ascii=false to output UTF-8.\n",
    "    \"\"\"\n",
    "    with open(fp, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "530314cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "write2json_file('IMCS-IR_test.json', rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e15189b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
